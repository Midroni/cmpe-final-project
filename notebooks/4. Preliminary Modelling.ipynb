{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Preliminary Modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train-Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = pd.read_pickle('../data/features_df.pkl')\n",
    "meta_df = pd.read_csv('../data/speechdetails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes all the text that was in before\n",
    "feat_df = feat_df.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feat_df.values\n",
    "y = meta_df['IC'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.3, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "       min_child_weight=1, missing=None, n_estimators=10, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 1.4418921 \t True 2.333\n",
      "Prediction 1.2277672 \t True 1.75\n",
      "Prediction 1.4418921 \t True 2.1\n",
      "Prediction 1.4089674 \t True 1.6\n",
      "Prediction 1.399816 \t True 2.5\n",
      "Prediction 1.3489909 \t True 1.9\n",
      "Prediction 1.3177259 \t True 1.625\n",
      "Prediction 1.3786222 \t True 1.5\n",
      "Prediction 1.4089674 \t True 1.4\n",
      "Prediction 1.3456593 \t True 1.2\n",
      "Prediction 1.4372418 \t True 1.875\n",
      "Prediction 1.1730297 \t True 1.8\n",
      "Prediction 1.365099 \t True 2.2\n",
      "Prediction 1.4418921 \t True 1.875\n",
      "Prediction 1.3140495 \t True 1.5\n",
      "Prediction 1.4418921 \t True 1.6\n",
      "Prediction 1.4418921 \t True 2.25\n",
      "Prediction 1.4418921 \t True 2.0\n",
      "Prediction 1.4418921 \t True 2.0\n",
      "Prediction 1.4089674 \t True 1.0\n",
      "Prediction 1.2490172 \t True 1.3\n",
      "Prediction 1.4089674 \t True 1.75\n",
      "Prediction 1.3861767 \t True 1.625\n",
      "Prediction 1.2954475 \t True 1.5\n",
      "Prediction 1.4290214 \t True 1.75\n",
      "Prediction 1.365099 \t True 1.7\n",
      "Prediction 1.4418921 \t True 2.1\n",
      "Prediction 1.2277672 \t True 2.0\n",
      "Prediction 1.3999717 \t True 1.8\n",
      "Prediction 1.3462541 \t True 2.1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_test)):\n",
    "    print('Prediction',preds[i],'\\t','True',y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.527372\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X,label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.222118</td>\n",
       "      <td>0.039675</td>\n",
       "      <td>1.220663</td>\n",
       "      <td>0.087276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.124399</td>\n",
       "      <td>0.036571</td>\n",
       "      <td>1.124137</td>\n",
       "      <td>0.089193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.037226</td>\n",
       "      <td>0.033902</td>\n",
       "      <td>1.037717</td>\n",
       "      <td>0.093476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.959700</td>\n",
       "      <td>0.031666</td>\n",
       "      <td>0.960710</td>\n",
       "      <td>0.097018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.890930</td>\n",
       "      <td>0.029815</td>\n",
       "      <td>0.892631</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.829778</td>\n",
       "      <td>0.028143</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.100951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.775398</td>\n",
       "      <td>0.027006</td>\n",
       "      <td>0.780085</td>\n",
       "      <td>0.102865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.727083</td>\n",
       "      <td>0.025794</td>\n",
       "      <td>0.733415</td>\n",
       "      <td>0.104681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.685052</td>\n",
       "      <td>0.025115</td>\n",
       "      <td>0.692368</td>\n",
       "      <td>0.105850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.647245</td>\n",
       "      <td>0.024850</td>\n",
       "      <td>0.655065</td>\n",
       "      <td>0.105256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.613789</td>\n",
       "      <td>0.024791</td>\n",
       "      <td>0.622806</td>\n",
       "      <td>0.103718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.585227</td>\n",
       "      <td>0.024402</td>\n",
       "      <td>0.595627</td>\n",
       "      <td>0.101948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.559477</td>\n",
       "      <td>0.024079</td>\n",
       "      <td>0.571584</td>\n",
       "      <td>0.099944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.537204</td>\n",
       "      <td>0.023444</td>\n",
       "      <td>0.549808</td>\n",
       "      <td>0.099581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.517683</td>\n",
       "      <td>0.023315</td>\n",
       "      <td>0.532311</td>\n",
       "      <td>0.098438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.500941</td>\n",
       "      <td>0.023614</td>\n",
       "      <td>0.517169</td>\n",
       "      <td>0.097381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.485401</td>\n",
       "      <td>0.023561</td>\n",
       "      <td>0.503486</td>\n",
       "      <td>0.096634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.471570</td>\n",
       "      <td>0.022867</td>\n",
       "      <td>0.492134</td>\n",
       "      <td>0.095815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.459720</td>\n",
       "      <td>0.022554</td>\n",
       "      <td>0.481855</td>\n",
       "      <td>0.093937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.449000</td>\n",
       "      <td>0.023243</td>\n",
       "      <td>0.473303</td>\n",
       "      <td>0.092490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.440403</td>\n",
       "      <td>0.023258</td>\n",
       "      <td>0.466044</td>\n",
       "      <td>0.090791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.431777</td>\n",
       "      <td>0.023196</td>\n",
       "      <td>0.459333</td>\n",
       "      <td>0.089490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.424337</td>\n",
       "      <td>0.023077</td>\n",
       "      <td>0.454039</td>\n",
       "      <td>0.088454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.418072</td>\n",
       "      <td>0.023150</td>\n",
       "      <td>0.449022</td>\n",
       "      <td>0.087383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.412273</td>\n",
       "      <td>0.023075</td>\n",
       "      <td>0.444953</td>\n",
       "      <td>0.085674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.407100</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>0.441671</td>\n",
       "      <td>0.084516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.402733</td>\n",
       "      <td>0.023353</td>\n",
       "      <td>0.438747</td>\n",
       "      <td>0.083262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.398828</td>\n",
       "      <td>0.022861</td>\n",
       "      <td>0.435676</td>\n",
       "      <td>0.082325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.394857</td>\n",
       "      <td>0.022865</td>\n",
       "      <td>0.433089</td>\n",
       "      <td>0.081847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.391200</td>\n",
       "      <td>0.023033</td>\n",
       "      <td>0.431179</td>\n",
       "      <td>0.080634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.388076</td>\n",
       "      <td>0.022866</td>\n",
       "      <td>0.429569</td>\n",
       "      <td>0.079902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.385383</td>\n",
       "      <td>0.023057</td>\n",
       "      <td>0.427902</td>\n",
       "      <td>0.078825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.383047</td>\n",
       "      <td>0.023006</td>\n",
       "      <td>0.426607</td>\n",
       "      <td>0.078425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.380296</td>\n",
       "      <td>0.022269</td>\n",
       "      <td>0.425145</td>\n",
       "      <td>0.077934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.378305</td>\n",
       "      <td>0.022219</td>\n",
       "      <td>0.424078</td>\n",
       "      <td>0.077143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.376264</td>\n",
       "      <td>0.022385</td>\n",
       "      <td>0.423301</td>\n",
       "      <td>0.076495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.374697</td>\n",
       "      <td>0.022435</td>\n",
       "      <td>0.422421</td>\n",
       "      <td>0.076182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.372823</td>\n",
       "      <td>0.021880</td>\n",
       "      <td>0.421592</td>\n",
       "      <td>0.075713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.371464</td>\n",
       "      <td>0.021719</td>\n",
       "      <td>0.420804</td>\n",
       "      <td>0.075394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.370264</td>\n",
       "      <td>0.021988</td>\n",
       "      <td>0.420102</td>\n",
       "      <td>0.074884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.369205</td>\n",
       "      <td>0.022131</td>\n",
       "      <td>0.419387</td>\n",
       "      <td>0.074367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.368138</td>\n",
       "      <td>0.021947</td>\n",
       "      <td>0.418915</td>\n",
       "      <td>0.074090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.367419</td>\n",
       "      <td>0.021861</td>\n",
       "      <td>0.418446</td>\n",
       "      <td>0.073820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.366683</td>\n",
       "      <td>0.022033</td>\n",
       "      <td>0.417997</td>\n",
       "      <td>0.073505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.365790</td>\n",
       "      <td>0.021861</td>\n",
       "      <td>0.417760</td>\n",
       "      <td>0.073181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.365267</td>\n",
       "      <td>0.021938</td>\n",
       "      <td>0.417438</td>\n",
       "      <td>0.072813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.364520</td>\n",
       "      <td>0.021745</td>\n",
       "      <td>0.417329</td>\n",
       "      <td>0.072552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.364031</td>\n",
       "      <td>0.021699</td>\n",
       "      <td>0.417267</td>\n",
       "      <td>0.072297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.363122</td>\n",
       "      <td>0.021498</td>\n",
       "      <td>0.417139</td>\n",
       "      <td>0.072008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.362438</td>\n",
       "      <td>0.021535</td>\n",
       "      <td>0.416870</td>\n",
       "      <td>0.071784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0          1.222118        0.039675        1.220663       0.087276\n",
       "1          1.124399        0.036571        1.124137       0.089193\n",
       "2          1.037226        0.033902        1.037717       0.093476\n",
       "3          0.959700        0.031666        0.960710       0.097018\n",
       "4          0.890930        0.029815        0.892631       0.100000\n",
       "5          0.829778        0.028143        0.832865       0.100951\n",
       "6          0.775398        0.027006        0.780085       0.102865\n",
       "7          0.727083        0.025794        0.733415       0.104681\n",
       "8          0.685052        0.025115        0.692368       0.105850\n",
       "9          0.647245        0.024850        0.655065       0.105256\n",
       "10         0.613789        0.024791        0.622806       0.103718\n",
       "11         0.585227        0.024402        0.595627       0.101948\n",
       "12         0.559477        0.024079        0.571584       0.099944\n",
       "13         0.537204        0.023444        0.549808       0.099581\n",
       "14         0.517683        0.023315        0.532311       0.098438\n",
       "15         0.500941        0.023614        0.517169       0.097381\n",
       "16         0.485401        0.023561        0.503486       0.096634\n",
       "17         0.471570        0.022867        0.492134       0.095815\n",
       "18         0.459720        0.022554        0.481855       0.093937\n",
       "19         0.449000        0.023243        0.473303       0.092490\n",
       "20         0.440403        0.023258        0.466044       0.090791\n",
       "21         0.431777        0.023196        0.459333       0.089490\n",
       "22         0.424337        0.023077        0.454039       0.088454\n",
       "23         0.418072        0.023150        0.449022       0.087383\n",
       "24         0.412273        0.023075        0.444953       0.085674\n",
       "25         0.407100        0.023597        0.441671       0.084516\n",
       "26         0.402733        0.023353        0.438747       0.083262\n",
       "27         0.398828        0.022861        0.435676       0.082325\n",
       "28         0.394857        0.022865        0.433089       0.081847\n",
       "29         0.391200        0.023033        0.431179       0.080634\n",
       "30         0.388076        0.022866        0.429569       0.079902\n",
       "31         0.385383        0.023057        0.427902       0.078825\n",
       "32         0.383047        0.023006        0.426607       0.078425\n",
       "33         0.380296        0.022269        0.425145       0.077934\n",
       "34         0.378305        0.022219        0.424078       0.077143\n",
       "35         0.376264        0.022385        0.423301       0.076495\n",
       "36         0.374697        0.022435        0.422421       0.076182\n",
       "37         0.372823        0.021880        0.421592       0.075713\n",
       "38         0.371464        0.021719        0.420804       0.075394\n",
       "39         0.370264        0.021988        0.420102       0.074884\n",
       "40         0.369205        0.022131        0.419387       0.074367\n",
       "41         0.368138        0.021947        0.418915       0.074090\n",
       "42         0.367419        0.021861        0.418446       0.073820\n",
       "43         0.366683        0.022033        0.417997       0.073505\n",
       "44         0.365790        0.021861        0.417760       0.073181\n",
       "45         0.365267        0.021938        0.417438       0.072813\n",
       "46         0.364520        0.021745        0.417329       0.072552\n",
       "47         0.364031        0.021699        0.417267       0.072297\n",
       "48         0.363122        0.021498        0.417139       0.072008\n",
       "49         0.362438        0.021535        0.416870       0.071784"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49    0.41687\n",
      "Name: test-rmse-mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print((cv_results[\"test-rmse-mean\"]).tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Boosting Trees and Feature Importance\n",
    "We can visualize individual trees from the fully boosted model that XGBoost creates using the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01383704 0.04233427 0.04702509 0.04291662 0.         0.\n",
      " 0.03668954 0.06519893 0.         0.05106923 0.03429625 0.03446979\n",
      " 0.02683082 0.04484382 0.07273355 0.06962946 0.         0.\n",
      " 0.         0.         0.         0.         0.03727857 0.09618485\n",
      " 0.07310277 0.07819398 0.04760987 0.08575562]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Cooper/anaconda3/envs/home/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/Cooper/anaconda3/envs/home/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=len(X[0]), activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X, y, epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
